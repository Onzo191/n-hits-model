{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install & import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['BIDV', 'VCB', 'EIB']\n",
    "START_DATE = '2019-01-01'\n",
    "END_DATE = '2024-06-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_directory = 'raw-data'\n",
    "raw_data_dict = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    file_name = f\"{dataset}_{START_DATE}_{END_DATE}.raw-data.csv\"\n",
    "    file_path = os.path.join(raw_directory, file_name)\n",
    "    \n",
    "    raw_data = pd.read_csv(file_path)\n",
    "    raw_data_dict[dataset] = raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(stock_data, start_date, end_date):\n",
    "    # drop null and duplicate values\n",
    "    stock_data.dropna(inplace=True)\n",
    "    stock_data.drop_duplicates(inplace=True)\n",
    "\n",
    "    # create a DataFrame with new date range\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "    stock_data.sort_values(by=['Date'], inplace=True, ascending=True)\n",
    "    timezones = stock_data['Date'].dt.tz\n",
    "\n",
    "    adjusted_start_date = pd.to_datetime(start_date).tz_localize(timezones)\n",
    "    adjusted_end_date = pd.to_datetime(end_date).tz_localize(timezones)\n",
    "    date_range = pd.date_range(start=adjusted_start_date, end=adjusted_end_date, freq='D')\n",
    "\n",
    "    filtered_dates = [date for date in date_range if date.weekday() < 5]  # 0-4: Monday-Friday\n",
    "    full_date = pd.DataFrame({'Date': filtered_dates})\n",
    "\n",
    "    filtered_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    data = pd.merge(full_date, stock_data[filtered_columns], on='Date', how='left')\n",
    "\n",
    "    # handle missing values\n",
    "    if data.iloc[0].isnull().any(): #first row\n",
    "        null_columns = data.isnull().columns\n",
    "\n",
    "        for col in null_columns:\n",
    "            first_valid_value = data[col].dropna().iloc[0]\n",
    "            data.loc[0, col] = first_valid_value\n",
    "\n",
    "    data.ffill(inplace=True) #another rows\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dict = {}\n",
    "\n",
    "for dataset, data in raw_data_dict.items():\n",
    "    processed_data = process_data(data, START_DATE, END_DATE)\n",
    "    processed_data_dict[dataset] = processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_directory = 'processed-data'\n",
    "\n",
    "if not os.path.exists(processed_directory):\n",
    "    os.makedirs(processed_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BIDV_2019-01-01_2024-06-01.processed-data.csv\n",
      "Saved VCB_2019-01-01_2024-06-01.processed-data.csv\n",
      "Saved EIB_2019-01-01_2024-06-01.processed-data.csv\n"
     ]
    }
   ],
   "source": [
    "for dataset, data in processed_data_dict.items():\n",
    "    file_name = f\"{dataset}_{START_DATE}_{END_DATE}.processed-data.csv\"\n",
    "    file_path = os.path.join(processed_directory, file_name)\n",
    "    data.to_csv(file_path)\n",
    "    print(f\"Saved {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
